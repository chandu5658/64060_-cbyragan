---
title: "FML 2"
author: "Chandu"
date: "`r Sys.Date()`"
output: html_document
---


```{r}
library(caret)
library(class)
library(e1071)


universal.df <- read.csv("C:\\Users\\its me\\OneDrive - Kent State University\\Desktop\\Rhistory\\UniversalBank (1).csv")
dim(universal.df)
t(t(names(universal.df)))
```


```{r}
universal.df <- universal.df[,-c(1,5)]
universal.df$Education <- as.factor(universal.df$Education)

```


```{r}

groups <- dummyVars(~., data = universal.df) 
universal_m.df <- as.data.frame(predict(groups,universal.df))

```



```{r}

set.seed(1)  
train.index <- sample(row.names(universal_m.df), 0.6*dim(universal_m.df)[1])
valid.index <- setdiff(row.names(universal_m.df), train.index)  
train.df <- universal_m.df[train.index,]
valid.df <- universal_m.df[valid.index,]
t(t(names(train.df)))

```


```{r}

library(caTools)
set.seed(1)
split <- sample.split(universal_m.df, SplitRatio = 0.6)
training_set <- subset(universal_m.df, split == TRUE)
validation_set <- subset(universal_m.df, split == FALSE)
print(paste("The size of the training set is:", nrow(training_set)))
print(paste("The size of the validation set is:", nrow(validation_set)))

```


```{r}

train.norm.df <- train.df[,-10] 
valid.norm.df <- valid.df[,-10]

norm.values <- preProcess(train.df[, -10], method=c("center", "scale"))
train.norm.df <- predict(norm.values, train.df[, -10])
valid.norm.df <- predict(norm.values, valid.df[, -10])

```

#QUESTION-1
Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 =
1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1, and
Credit Card = 1. Perform a k-NN classification with all predictors except ID and ZIP code
using k = 1. Remember to transform categorical predictors with more than two categories
into dummy variables first. Specify the success class as 1 (loan acceptance), and use the
default cutoff value of 0.5. How would this customer be classified?
```{r}

new_customer <- data.frame(
  Age = 40,
  Experience = 10,
  Income = 84,
  Family = 2,
  CCAvg = 2,
  Education.1 = 0,
  Education.2 = 1,
  Education.3 = 0,
  Mortgage = 0,
  Securities.Account = 0,
  CD.Account = 0,
  Online = 1,
  CreditCard = 1
)


new.cust.norm <- new_customer
new.cust.norm <- predict(norm.values,new_customer)

knn.pred1 <- class::knn(train = train.norm.df, 
                       test = new.cust.norm, 
                       cl = train.df$Personal.Loan, 
                       k = 1)
knn.pred1

```

#QUESTION-2
What is a choice of k that balances between overfitting and ignoring the predictor
information?

#calculating the accuracy of each value of k
```{r}

accuracy.df <- data.frame(k = seq(1, 15, 1), overallaccuracy = rep(0, 15))
for(i in 1:15) {
  knn.pred <- class::knn(train = train.norm.df, 
                         test = valid.norm.df, 
                         cl = train.df$Personal.Loan, k = i)
  accuracy.df[i, 2] <- confusionMatrix(knn.pred, 
                                       as.factor(valid.df$Personal.Loan),positive = "1")$overall[1]
}

which(accuracy.df[,2] == max(accuracy.df[,2])) 

plot(accuracy.df$k,accuracy.df$overallaccuracy)

```


#QUESTION-3

Show the confusion matrix for the validation data that results from using the best k.
```{r}

best_k <- which.max(accuracy.df$overallaccuracy)


best_k_pred <- class::knn(train = train.norm.df, 
                         test = valid.norm.df, 
                         cl = train.df$Personal.Loan, k = best_k)


confusion_matrix <- confusionMatrix(best_k_pred, 
                                    as.factor(valid.df$Personal.Loan), 
                                    positive = "1")
confusion_matrix

```


